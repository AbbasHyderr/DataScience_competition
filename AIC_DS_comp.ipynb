{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7fGTuRsOBTR",
        "outputId": "580a2bab-eb86-4e3b-d764-4b85c6eae9c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.11.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdBY-gBhYH2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"pakistanproperty1.csv\")  # Replace with your preprocessed dataset file\n",
        "\n",
        "# Drop the area_unit column\n",
        "X = preprocessed_data.drop([\"price\"], axis=1).values\n",
        "y = preprocessed_data[\"price\"].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"linear\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(\"Mean Squared Error:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7jcFSmjR8ef",
        "outputId": "20665a38-469f-46ba-8e4c-ec20a3558982"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1804/1804 [==============================] - 12s 5ms/step - loss: 1867974289915904.0000\n",
            "Epoch 2/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1801267810664448.0000\n",
            "Epoch 3/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1729442669920256.0000\n",
            "Epoch 4/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1875570879102976.0000\n",
            "Epoch 5/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1557945699532800.0000\n",
            "Epoch 6/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1403440693510144.0000\n",
            "Epoch 7/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1310714228637696.0000\n",
            "Epoch 8/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1257521595547648.0000\n",
            "Epoch 9/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1181893261262848.0000\n",
            "Epoch 10/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1166882350563328.0000\n",
            "Epoch 11/100\n",
            "1804/1804 [==============================] - 11s 6ms/step - loss: 1144399941599232.0000\n",
            "Epoch 12/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1124009718579200.0000\n",
            "Epoch 13/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1098293803220992.0000\n",
            "Epoch 14/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1080670143119360.0000\n",
            "Epoch 15/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1064451675521024.0000\n",
            "Epoch 16/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1080812011257856.0000\n",
            "Epoch 17/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1029192275722240.0000\n",
            "Epoch 18/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1024085089845248.0000\n",
            "Epoch 19/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1010460312731648.0000\n",
            "Epoch 20/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 1003109878857728.0000\n",
            "Epoch 21/100\n",
            "1804/1804 [==============================] - 12s 7ms/step - loss: 987342181498880.0000\n",
            "Epoch 22/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 991564939657216.0000\n",
            "Epoch 23/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 979091817758720.0000\n",
            "Epoch 24/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 991387235385344.0000\n",
            "Epoch 25/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 963320966283264.0000\n",
            "Epoch 26/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 965337990299648.0000\n",
            "Epoch 27/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 961172274675712.0000\n",
            "Epoch 28/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 956546058027008.0000\n",
            "Epoch 29/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 946760176369664.0000\n",
            "Epoch 30/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 914744751947776.0000\n",
            "Epoch 31/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 963462297550848.0000\n",
            "Epoch 32/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 956015294021632.0000\n",
            "Epoch 33/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 913209234030592.0000\n",
            "Epoch 34/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 912454527746048.0000\n",
            "Epoch 35/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 930673107927040.0000\n",
            "Epoch 36/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 930034097324032.0000\n",
            "Epoch 37/100\n",
            "1804/1804 [==============================] - 11s 6ms/step - loss: 900515323969536.0000\n",
            "Epoch 38/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 896566034432000.0000\n",
            "Epoch 39/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 907072396853248.0000\n",
            "Epoch 40/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 928273429168128.0000\n",
            "Epoch 41/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 942999596957696.0000\n",
            "Epoch 42/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 897871301836800.0000\n",
            "Epoch 43/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 902822728040448.0000\n",
            "Epoch 44/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 893186297823232.0000\n",
            "Epoch 45/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 847369868410880.0000\n",
            "Epoch 46/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 837636868538368.0000\n",
            "Epoch 47/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 825220722065408.0000\n",
            "Epoch 48/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 859622000820224.0000\n",
            "Epoch 49/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 874398097604608.0000\n",
            "Epoch 50/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 846569192554496.0000\n",
            "Epoch 51/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 843998654627840.0000\n",
            "Epoch 52/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 921065467412480.0000\n",
            "Epoch 53/100\n",
            "1804/1804 [==============================] - 11s 6ms/step - loss: 858374111494144.0000\n",
            "Epoch 54/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 889800588525568.0000\n",
            "Epoch 55/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 953840564174848.0000\n",
            "Epoch 56/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 834022318014464.0000\n",
            "Epoch 57/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 870170977370112.0000\n",
            "Epoch 58/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 879520852738048.0000\n",
            "Epoch 59/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 831811819143168.0000\n",
            "Epoch 60/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 830698080436224.0000\n",
            "Epoch 61/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 832148906967040.0000\n",
            "Epoch 62/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 799472057581568.0000\n",
            "Epoch 63/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 844490227056640.0000\n",
            "Epoch 64/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 847870232100864.0000\n",
            "Epoch 65/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 811108935925760.0000\n",
            "Epoch 66/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 790044335931392.0000\n",
            "Epoch 67/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 788530963939328.0000\n",
            "Epoch 68/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 768365756940288.0000\n",
            "Epoch 69/100\n",
            "1804/1804 [==============================] - 12s 6ms/step - loss: 801653968076800.0000\n",
            "Epoch 70/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 818670695612416.0000\n",
            "Epoch 71/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 776418552184832.0000\n",
            "Epoch 72/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 875584448102400.0000\n",
            "Epoch 73/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 812696396103680.0000\n",
            "Epoch 74/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 823491326640128.0000\n",
            "Epoch 75/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 820910453948416.0000\n",
            "Epoch 76/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 808013875118080.0000\n",
            "Epoch 77/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 795860057194496.0000\n",
            "Epoch 78/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 793750959816704.0000\n",
            "Epoch 79/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 801445125292032.0000\n",
            "Epoch 80/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 812602577911808.0000\n",
            "Epoch 81/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 784046548320256.0000\n",
            "Epoch 82/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 813570421948416.0000\n",
            "Epoch 83/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 809587913523200.0000\n",
            "Epoch 84/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 814401363902464.0000\n",
            "Epoch 85/100\n",
            "1804/1804 [==============================] - 12s 6ms/step - loss: 844754837307392.0000\n",
            "Epoch 86/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 785467578515456.0000\n",
            "Epoch 87/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 792222287003648.0000\n",
            "Epoch 88/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 851163733819392.0000\n",
            "Epoch 89/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 805322205691904.0000\n",
            "Epoch 90/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 760127405686784.0000\n",
            "Epoch 91/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 815553824423936.0000\n",
            "Epoch 92/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 785497710395392.0000\n",
            "Epoch 93/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 838159042609152.0000\n",
            "Epoch 94/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 750466480734208.0000\n",
            "Epoch 95/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 760580591845376.0000\n",
            "Epoch 96/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 749367573086208.0000\n",
            "Epoch 97/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 776751680585728.0000\n",
            "Epoch 98/100\n",
            "1804/1804 [==============================] - 10s 6ms/step - loss: 815989428060160.0000\n",
            "Epoch 99/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 755701106343936.0000\n",
            "Epoch 100/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 763670216835072.0000\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 513231378448384.0000\n",
            "Mean Squared Error: 513231378448384.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = np.sqrt(loss)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EvSa2ZpYJ8L",
        "outputId": "7ff45bf9-c077-40ee-88a8-994954555a4c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 22654610.534025606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model\n",
        "best_model =random_search_result.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = np.mean((y_pred - y_test) ** 2)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3B9Jjt5aena",
        "outputId": "e61742c1-de4b-48ea-b865-744aee41c52f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1901698153303420.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"pakistanproperty1.csv\")  # Replace with your preprocessed dataset file\n",
        "\n",
        "# Drop the area_unit column\n",
        "X = preprocessed_data.drop([\"price\"], axis=1).values\n",
        "y = preprocessed_data[\"price\"].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
        "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1, activation=\"linear\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(\"Mean Squared Error:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIza29pLZGu1",
        "outputId": "64fb8a7d-3e1a-4d05-a97b-6a362aef9283"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1804/1804 [==============================] - 13s 6ms/step - loss: 1857315389046784.0000\n",
            "Epoch 2/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1805355948441600.0000\n",
            "Epoch 3/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1730608485105664.0000\n",
            "Epoch 4/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1828055253254144.0000\n",
            "Epoch 5/100\n",
            "1804/1804 [==============================] - 8s 4ms/step - loss: 1572832995704832.0000\n",
            "Epoch 6/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1481196513001472.0000\n",
            "Epoch 7/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1371590558220288.0000\n",
            "Epoch 8/100\n",
            "1804/1804 [==============================] - 8s 4ms/step - loss: 1258522322927616.0000\n",
            "Epoch 9/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1230141044817920.0000\n",
            "Epoch 10/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1167370366222336.0000\n",
            "Epoch 11/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 1160028790718464.0000\n",
            "Epoch 12/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1106345189179392.0000\n",
            "Epoch 13/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1073751017914368.0000\n",
            "Epoch 14/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1060995904569344.0000\n",
            "Epoch 15/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 1044090711965696.0000\n",
            "Epoch 16/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 1049833955655680.0000\n",
            "Epoch 17/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1017797928812544.0000\n",
            "Epoch 18/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 1023210795565056.0000\n",
            "Epoch 19/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1014579790348288.0000\n",
            "Epoch 20/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1009142093316096.0000\n",
            "Epoch 21/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 992535065395200.0000\n",
            "Epoch 22/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 983181431930880.0000\n",
            "Epoch 23/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 997143699521536.0000\n",
            "Epoch 24/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 981025492566016.0000\n",
            "Epoch 25/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 979483532197888.0000\n",
            "Epoch 26/100\n",
            "1804/1804 [==============================] - 11s 6ms/step - loss: 980807724302336.0000\n",
            "Epoch 27/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 963781735743488.0000\n",
            "Epoch 28/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 934353290919936.0000\n",
            "Epoch 29/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 952617303801856.0000\n",
            "Epoch 30/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 931774297276416.0000\n",
            "Epoch 31/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 906612164263936.0000\n",
            "Epoch 32/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 918734776565760.0000\n",
            "Epoch 33/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 906393456476160.0000\n",
            "Epoch 34/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 927465572663296.0000\n",
            "Epoch 35/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 885927467548672.0000\n",
            "Epoch 36/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 918189718372352.0000\n",
            "Epoch 37/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 924605795532800.0000\n",
            "Epoch 38/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 967053024428032.0000\n",
            "Epoch 39/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 936124562276352.0000\n",
            "Epoch 40/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 909158006128640.0000\n",
            "Epoch 41/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 938595443539968.0000\n",
            "Epoch 42/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 911983423520768.0000\n",
            "Epoch 43/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 880976578215936.0000\n",
            "Epoch 44/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 973934971322368.0000\n",
            "Epoch 45/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 909479457587200.0000\n",
            "Epoch 46/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 870959439413248.0000\n",
            "Epoch 47/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 851335733837824.0000\n",
            "Epoch 48/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 835731111018496.0000\n",
            "Epoch 49/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 950101795143680.0000\n",
            "Epoch 50/100\n",
            "1804/1804 [==============================] - 11s 6ms/step - loss: 866221553614848.0000\n",
            "Epoch 51/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 901904007692288.0000\n",
            "Epoch 52/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 994567323123712.0000\n",
            "Epoch 53/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 909585556701184.0000\n",
            "Epoch 54/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 857311107088384.0000\n",
            "Epoch 55/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 893899732156416.0000\n",
            "Epoch 56/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 1123138846851072.0000\n",
            "Epoch 57/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 811938200158208.0000\n",
            "Epoch 58/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 842119069564928.0000\n",
            "Epoch 59/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 870795425349632.0000\n",
            "Epoch 60/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 889834814046208.0000\n",
            "Epoch 61/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 833133461110784.0000\n",
            "Epoch 62/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 809941845671936.0000\n",
            "Epoch 63/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 895516451799040.0000\n",
            "Epoch 64/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 834107210727424.0000\n",
            "Epoch 65/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 898209194967040.0000\n",
            "Epoch 66/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 800668675735552.0000\n",
            "Epoch 67/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 803385041223680.0000\n",
            "Epoch 68/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 824766126620672.0000\n",
            "Epoch 69/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 800163949969408.0000\n",
            "Epoch 70/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 974312391573504.0000\n",
            "Epoch 71/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 832871669432320.0000\n",
            "Epoch 72/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 840120164941824.0000\n",
            "Epoch 73/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 817628897607680.0000\n",
            "Epoch 74/100\n",
            "1804/1804 [==============================] - 11s 6ms/step - loss: 797771787403264.0000\n",
            "Epoch 75/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 788684173475840.0000\n",
            "Epoch 76/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 794068518961152.0000\n",
            "Epoch 77/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 847823054569472.0000\n",
            "Epoch 78/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 794265483476992.0000\n",
            "Epoch 79/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 804401606295552.0000\n",
            "Epoch 80/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 805342271242240.0000\n",
            "Epoch 81/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 821908362756096.0000\n",
            "Epoch 82/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 760675215343616.0000\n",
            "Epoch 83/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 762946447736832.0000\n",
            "Epoch 84/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 775568148660224.0000\n",
            "Epoch 85/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 799218251857920.0000\n",
            "Epoch 86/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 815373301579776.0000\n",
            "Epoch 87/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 830355892338688.0000\n",
            "Epoch 88/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 794299440562176.0000\n",
            "Epoch 89/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 791269542461440.0000\n",
            "Epoch 90/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 773832042348544.0000\n",
            "Epoch 91/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 786894581399552.0000\n",
            "Epoch 92/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 785433017450496.0000\n",
            "Epoch 93/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 775982881439744.0000\n",
            "Epoch 94/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 780233892429824.0000\n",
            "Epoch 95/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 814068906590208.0000\n",
            "Epoch 96/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 767132161802240.0000\n",
            "Epoch 97/100\n",
            "1804/1804 [==============================] - 8s 5ms/step - loss: 763635186008064.0000\n",
            "Epoch 98/100\n",
            "1804/1804 [==============================] - 11s 6ms/step - loss: 730401735704576.0000\n",
            "Epoch 99/100\n",
            "1804/1804 [==============================] - 9s 5ms/step - loss: 745482909384704.0000\n",
            "Epoch 100/100\n",
            "1804/1804 [==============================] - 10s 5ms/step - loss: 769028121427968.0000\n",
            "451/451 [==============================] - 1s 2ms/step - loss: 484119419027456.0000\n",
            "Mean Squared Error: 484119419027456.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-estimator\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GQRYEKBuHYI",
        "outputId": "5f278ca4-f715-4ddb-aa78-3a2a547d2f81"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-estimator in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kMKUP6O2gZ4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}